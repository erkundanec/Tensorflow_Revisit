{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Decision Tree (GBDT)\n",
    "Implement a Gradient Boosted Decision Tree (GBDT) with TensorFlow. This example is using the Boston Housing Value dataset as training samples. The example supports both Classification (2 classes: value > $23000 or not) and Regression (raw home value as target)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston Housing Dataset\n",
    "\n",
    "**Link:** https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\n",
    "\n",
    "**Description:**\n",
    "\n",
    "The dataset contains information collected by the U.S Census Service concerning housing in the area of Boston Mass. It was obtained from the StatLib archive (http://lib.stat.cmu.edu/datasets/boston), and has been used extensively throughout the literature to benchmark algorithms. However, these comparisons were primarily done outside of Delve and are thus somewhat suspect. The dataset is small in size with only 506 cases.\n",
    "\n",
    "The data was originally published by Harrison, D. and Rubinfeld, D.L. `Hedonic prices and the demand for clean air', J. Environ. Economics & Management, vol.5, 81-102, 1978.`\n",
    "\n",
    "*For the full features list, please see the link above*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Ignore all GPUs (current TF GBDT does not support GPU).\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters.\n",
    "num_classes = 2 # Total classes: greater or equal to $23,000, or not (See notes below).\n",
    "num_features = 13 # data features size.\n",
    "\n",
    "# Training parameters.\n",
    "max_steps = 2000\n",
    "batch_size = 256\n",
    "learning_rate = 1.0\n",
    "l1_regul = 0.0\n",
    "l2_regul = 0.1\n",
    "\n",
    "# GBDT parameters.\n",
    "num_batches_per_layer = 1000\n",
    "num_trees = 10\n",
    "max_depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Boston Housing Dataset.\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "# For classification purpose, we build 2 classes: price greater or lower than $23,000\n",
    "def to_binary_class(y):\n",
    "    for i, label in enumerate(y):\n",
    "        if label >= 23.0:\n",
    "            y[i] = 1\n",
    "        else:\n",
    "            y[i] = 0\n",
    "    return y\n",
    "\n",
    "y_train_binary = to_binary_class(copy.deepcopy(y_train))\n",
    "y_test_binary = to_binary_class(copy.deepcopy(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the input function.\n",
    "train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_train}, y=y_train_binary,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "\n",
    "test_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_test}, y=y_test_binary,\n",
    "    batch_size=batch_size, num_epochs=1, shuffle=False)\n",
    "\n",
    "test_train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_train}, y=y_train_binary,\n",
    "    batch_size=batch_size, num_epochs=1, shuffle=False)\n",
    "\n",
    "# GBDT Models from TF Estimator requires 'feature_column' data format.\n",
    "feature_columns = [tf.feature_column.numeric_column(key='x', shape=(num_features,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_estimator.python.estimator.api._v2.estimator' has no attribute 'BoostedTreesClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\07_Github_Repository\\Tensorflow_Revisit\\04_gradient_boosted_trees.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/07_Github_Repository/Tensorflow_Revisit/04_gradient_boosted_trees.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m gbdt_classifier \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mestimator\u001b[39m.\u001b[39;49mBoostedTreesClassifier(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/07_Github_Repository/Tensorflow_Revisit/04_gradient_boosted_trees.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     n_batches_per_layer\u001b[39m=\u001b[39mnum_batches_per_layer,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/07_Github_Repository/Tensorflow_Revisit/04_gradient_boosted_trees.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     feature_columns\u001b[39m=\u001b[39mfeature_columns, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/07_Github_Repository/Tensorflow_Revisit/04_gradient_boosted_trees.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     n_classes\u001b[39m=\u001b[39mnum_classes,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/07_Github_Repository/Tensorflow_Revisit/04_gradient_boosted_trees.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39mlearning_rate, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/07_Github_Repository/Tensorflow_Revisit/04_gradient_boosted_trees.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     n_trees\u001b[39m=\u001b[39mnum_trees,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/07_Github_Repository/Tensorflow_Revisit/04_gradient_boosted_trees.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     max_depth\u001b[39m=\u001b[39mmax_depth,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/07_Github_Repository/Tensorflow_Revisit/04_gradient_boosted_trees.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     l1_regularization\u001b[39m=\u001b[39ml1_regul, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/07_Github_Repository/Tensorflow_Revisit/04_gradient_boosted_trees.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     l2_regularization\u001b[39m=\u001b[39ml2_regul\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/07_Github_Repository/Tensorflow_Revisit/04_gradient_boosted_trees.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow_estimator.python.estimator.api._v2.estimator' has no attribute 'BoostedTreesClassifier'"
     ]
    }
   ],
   "source": [
    "gbdt_classifier = tf.estimator.BoostedTreesClassifier(\n",
    "    n_batches_per_layer=num_batches_per_layer,\n",
    "    feature_columns=feature_columns, \n",
    "    n_classes=num_classes,\n",
    "    learning_rate=learning_rate, \n",
    "    n_trees=num_trees,\n",
    "    max_depth=max_depth,\n",
    "    l1_regularization=l1_regul, \n",
    "    l2_regularization=l2_regul\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gbdt_classifier.train(train_input_fn, max_steps=max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_classifier.evaluate(test_train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_classifier.evaluate(test_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the input function.\n",
    "train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_train}, y=y_train,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "test_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_test}, y=y_test,\n",
    "    batch_size=batch_size, num_epochs=1, shuffle=False)\n",
    "# GBDT Models from TF Estimator requires 'feature_column' data format.\n",
    "feature_columns = [tf.feature_column.numeric_column(key='x', shape=(num_features,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_regressor = tf.estimator.BoostedTreesRegressor(\n",
    "    n_batches_per_layer=num_batches_per_layer,\n",
    "    feature_columns=feature_columns, \n",
    "    learning_rate=learning_rate, \n",
    "    n_trees=num_trees,\n",
    "    max_depth=max_depth,\n",
    "    l1_regularization=l1_regul, \n",
    "    l2_regularization=l2_regul\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gbdt_regressor.train(train_input_fn, max_steps=max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_regressor.evaluate(test_input_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
